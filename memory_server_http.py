# memory_server_http.py
# é€šç”¨ MCP è®°å¿†æœåŠ¡ - äº‘ç«¯ç‰ˆæœ¬ (HTTP/SSE ä¼ è¾“)
# ä½¿ç”¨ PostgreSQL + Gemini Embedding è¯­ä¹‰æœç´¢
# å…¼å®¹ä»»ä½•æ”¯æŒ MCP åè®®çš„å®¢æˆ·ç«¯

import os
import requests
import numpy as np
from datetime import datetime
from mcp.server import Server
from mcp.server.sse import SseServerTransport
from mcp.types import Tool, TextContent
from starlette.applications import Starlette
from starlette.routing import Route, Mount
from starlette.responses import JSONResponse
import uvicorn
import psycopg2
from psycopg2.extras import RealDictCursor

# é…ç½®
DATABASE_URL = os.environ.get("DATABASE_URL")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
# ä½¿ç”¨æœ€æ–°çš„ gemini-embedding-001ï¼ˆ3072ç»´ï¼Œ100+è¯­è¨€æ”¯æŒï¼‰
# æ³¨æ„ï¼šå¦‚æœä» text-embedding-004 åˆ‡æ¢ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆæ‰€æœ‰ embedding
GEMINI_EMBEDDING_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:embedContent"

# å·¥å…·åç§°å‰ç¼€ï¼ˆç”¨äºåŒºåˆ†å¤šä¸ªå®ä¾‹ï¼Œé¿å…é‡å¤å£°æ˜é”™è¯¯ï¼‰
# è®¾ç½®ç¯å¢ƒå˜é‡ TOOL_PREFIX æ¥è‡ªå®šä¹‰ï¼Œä¾‹å¦‚ TOOL_PREFIX=work_ æˆ– TOOL_PREFIX=personal_
TOOL_PREFIX = os.environ.get("TOOL_PREFIX", "")

# Embedding ç¼“å­˜ï¼ˆå‡å°‘ API è°ƒç”¨ï¼ŒåŠ é€Ÿå“åº”ï¼‰
EMBEDDING_CACHE = {}
EMBEDDING_CACHE_MAX_SIZE = 100  # æœ€å¤šç¼“å­˜ 100 æ¡

# æœç´¢æ¨¡å¼ï¼šsemanticï¼ˆè¯­ä¹‰æœç´¢ï¼Œæ™ºèƒ½ä½†æ…¢ï¼‰æˆ– keywordï¼ˆå…³é”®è¯æœç´¢ï¼Œå¿«ä½†éœ€ç²¾ç¡®åŒ¹é…ï¼‰
# è®¾ç½®ç¯å¢ƒå˜é‡ SEARCH_MODE æ¥åˆ‡æ¢ï¼Œé»˜è®¤ä¸º semantic
SEARCH_MODE = os.environ.get("SEARCH_MODE", "semantic").lower()

# è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 3 æ¡ï¼Œå‡å°‘ä¼ è¾“å’Œå¤„ç†æ—¶é—´ï¼‰
MAX_RESULTS = int(os.environ.get("MAX_RESULTS", "3"))

# æ¸è¿›å¼æ³¨å…¥ï¼šè¿½è¸ª recall_memory è°ƒç”¨æ¬¡æ•°
# ç®€å•å®ç°ï¼šåŸºäºæ—¶é—´é—´éš”åˆ¤æ–­æ˜¯å¦ä¸ºæ–°ä¼šè¯
RECALL_COUNTER = {"count": 0, "last_call": None}
RECALL_SESSION_TIMEOUT = 300  # 5 åˆ†é’Ÿæ— è°ƒç”¨è§†ä¸ºæ–°ä¼šè¯

# ========== è®°å¿†ç¼“å­˜ ==========
# ç¼“å­˜æ‰€æœ‰è®°å¿†åˆ°å†…å­˜ï¼Œé¿å…æ¯æ¬¡ recall éƒ½æŸ¥æ•°æ®åº“
_memory_cache: list[dict] = []
_cache_initialized = False


def init_memory_cache():
    """åˆå§‹åŒ–è®°å¿†ç¼“å­˜ï¼ˆä»æ•°æ®åº“åŠ è½½åˆ°å†…å­˜ï¼‰"""
    global _memory_cache, _cache_initialized
    if not DATABASE_URL:
        _cache_initialized = True
        return

    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT id, content, tags, embedding, priority, category, created_at, updated_at FROM memories ORDER BY id")
        rows = cur.fetchall()
        cur.close()
        conn.close()

        _memory_cache = []
        for row in rows:
            _memory_cache.append({
                "id": row["id"],
                "content": row["content"],
                "tags": row["tags"] or [],
                "embedding": row["embedding"] or [],
                "priority": row.get("priority", 3) or 3,
                "category": row.get("category", "general") or "general",
                "created_at": row["created_at"].isoformat() if row["created_at"] else None,
                "updated_at": row["updated_at"].isoformat() if row.get("updated_at") else None
            })
        _cache_initialized = True
        print(f"[CACHE] å·²åŠ è½½ {len(_memory_cache)} æ¡è®°å¿†åˆ°å†…å­˜", flush=True)
    except Exception as e:
        print(f"[CACHE ERROR] {e}", flush=True)
        _cache_initialized = True


def get_cached_memories() -> list[dict]:
    """è·å–ç¼“å­˜çš„è®°å¿†ï¼ˆå¦‚æœæœªåˆå§‹åŒ–åˆ™å…ˆåˆå§‹åŒ–ï¼‰"""
    global _cache_initialized
    if not _cache_initialized:
        init_memory_cache()
    return _memory_cache


def add_to_cache(memory: dict):
    """æ·»åŠ è®°å¿†åˆ°ç¼“å­˜"""
    global _memory_cache
    _memory_cache.append(memory)


def update_cache(memory_id: int, **updates):
    """æ›´æ–°ç¼“å­˜ä¸­çš„è®°å¿†"""
    global _memory_cache
    for m in _memory_cache:
        if m["id"] == memory_id:
            m.update(updates)
            break


def remove_from_cache(memory_id: int):
    """ä»ç¼“å­˜ä¸­åˆ é™¤è®°å¿†"""
    global _memory_cache
    _memory_cache = [m for m in _memory_cache if m["id"] != memory_id]

# åˆ›å»º MCP Server
server_name = os.environ.get("SERVER_NAME", "memory-server")
server = Server(server_name)


def get_embedding(text: str, use_cache: bool = True) -> list[float]:
    """ä½¿ç”¨ Gemini è·å–æ–‡æœ¬çš„ embedding å‘é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global EMBEDDING_CACHE

    # ç”Ÿæˆç¼“å­˜ keyï¼ˆå–å‰ 200 å­—ç¬¦ï¼Œé¿å… key è¿‡é•¿ï¼‰
    cache_key = text[:200].strip().lower()

    # æ£€æŸ¥ç¼“å­˜
    if use_cache and cache_key in EMBEDDING_CACHE:
        print(f"[EMBEDDING] ç¼“å­˜å‘½ä¸­: {text[:30]}...", flush=True)
        return EMBEDDING_CACHE[cache_key]

    if not GEMINI_API_KEY:
        print("[EMBEDDING] è­¦å‘Š: GEMINI_API_KEY æœªè®¾ç½®", flush=True)
        return []

    try:
        url = f"{GEMINI_EMBEDDING_URL}?key={GEMINI_API_KEY}"

        payload = {
            "content": {
                "parts": [{"text": text}]
            }
        }

        response = requests.post(url, json=payload, timeout=10)

        if response.status_code == 200:
            result = response.json()
            embedding = result.get("embedding", {}).get("values", [])
            print(f"[EMBEDDING] API æˆåŠŸ: {text[:30]}... (ç»´åº¦: {len(embedding)})", flush=True)

            # å­˜å…¥ç¼“å­˜
            if use_cache and embedding:
                # ç®€å•çš„ LRUï¼šè¶…è¿‡ä¸Šé™æ—¶åˆ é™¤æœ€æ—©çš„
                if len(EMBEDDING_CACHE) >= EMBEDDING_CACHE_MAX_SIZE:
                    oldest_key = next(iter(EMBEDDING_CACHE))
                    del EMBEDDING_CACHE[oldest_key]
                EMBEDDING_CACHE[cache_key] = embedding

            return embedding
        else:
            print(f"[EMBEDDING] APIé”™è¯¯: {response.status_code}", flush=True)
    except Exception as e:
        print(f"[EMBEDDING] å¼‚å¸¸: {e}", flush=True)
    return []


def translate_query(query: str) -> list[str]:
    """ä½¿ç”¨ Gemini Flash å°†æŸ¥è¯¢è¯ç¿»è¯‘æˆå¤šè¯­è¨€ï¼Œè¿”å›ç¿»è¯‘åˆ—è¡¨"""
    if not GEMINI_API_KEY:
        return []

    # æ£€æµ‹æ˜¯å¦éœ€è¦ç¿»è¯‘ï¼ˆçº¯ ASCII å¤§æ¦‚ç‡æ˜¯è‹±æ–‡ï¼Œå¦åˆ™å¯èƒ½æ˜¯ä¸­æ—¥éŸ©ï¼‰
    is_ascii = all(ord(c) < 128 for c in query.replace(" ", ""))

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

        # æ ¹æ®æŸ¥è¯¢è¯­è¨€é€‰æ‹©ç¿»è¯‘æ–¹å‘
        if is_ascii:
            prompt = f"Translate '{query}' to Chinese and Japanese. Return ONLY the translations, one per line, no explanations."
        else:
            prompt = f"Translate '{query}' to English. Return ONLY the translation, no explanations."

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"maxOutputTokens": 50, "temperature": 0}
        }

        response = requests.post(url, json=payload, timeout=5)

        if response.status_code == 200:
            result = response.json()
            text = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
            translations = [t.strip() for t in text.strip().split("\n") if t.strip() and t.strip() != query]
            print(f"[TRANSLATE] '{query}' -> {translations}", flush=True)
            return translations[:3]  # æœ€å¤šè¿”å› 3 ä¸ªç¿»è¯‘
    except Exception as e:
        print(f"[TRANSLATE] é”™è¯¯: {e}", flush=True)

    return []


def cosine_similarity(vec1: list[float], vec2: list[float]) -> float:
    """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    if not vec1 or not vec2:
        return 0.0
    a = np.array(vec1)
    b = np.array(vec2)
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)


def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    conn = get_db_connection()
    cur = conn.cursor()
    # åˆ›å»ºè¡¨ï¼ŒåŒ…å« embeddingã€priorityã€category åˆ—
    cur.execute("""
        CREATE TABLE IF NOT EXISTS memories (
            id SERIAL PRIMARY KEY,
            content TEXT NOT NULL,
            tags TEXT[] DEFAULT '{}',
            embedding FLOAT8[],
            priority INTEGER DEFAULT 3,
            category VARCHAR(50) DEFAULT 'general',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    # åŠ¨æ€æ·»åŠ ç¼ºå¤±çš„åˆ—
    cur.execute("""
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns
                WHERE table_name = 'memories' AND column_name = 'embedding'
            ) THEN
                ALTER TABLE memories ADD COLUMN embedding FLOAT8[];
            END IF;
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns
                WHERE table_name = 'memories' AND column_name = 'priority'
            ) THEN
                ALTER TABLE memories ADD COLUMN priority INTEGER DEFAULT 3;
            END IF;
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns
                WHERE table_name = 'memories' AND column_name = 'category'
            ) THEN
                ALTER TABLE memories ADD COLUMN category VARCHAR(50) DEFAULT 'general';
            END IF;
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns
                WHERE table_name = 'memories' AND column_name = 'updated_at'
            ) THEN
                ALTER TABLE memories ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP;
            END IF;
        END $$;
    """)
    conn.commit()
    cur.close()
    conn.close()


def load_memories() -> list[dict]:
    """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰è®°å¿†"""
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute("SELECT id, content, tags, embedding, priority, category, created_at, updated_at FROM memories ORDER BY id")
    rows = cur.fetchall()
    cur.close()
    conn.close()

    memories = []
    for row in rows:
        memories.append({
            "id": row["id"],
            "content": row["content"],
            "tags": row["tags"] or [],
            "embedding": row["embedding"] or [],
            "priority": row.get("priority", 3) or 3,
            "category": row.get("category", "general") or "general",
            "created_at": row["created_at"].isoformat() if row["created_at"] else None,
            "updated_at": row["updated_at"].isoformat() if row.get("updated_at") else None
        })
    return memories


def save_memory_to_db(content: str, tags: list, priority: int = 3, category: str = "general") -> dict:
    """ä¿å­˜æ–°è®°å¿†åˆ°æ•°æ®åº“å¹¶æ›´æ–°ç¼“å­˜"""
    # ç”Ÿæˆ embedding
    embedding = get_embedding(content)

    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute(
        "INSERT INTO memories (content, tags, embedding, priority, category) VALUES (%s, %s, %s, %s, %s) RETURNING id, created_at",
        (content, tags, embedding if embedding else None, priority, category)
    )
    result = cur.fetchone()
    conn.commit()
    cur.close()
    conn.close()

    memory_data = {
        "id": result["id"],
        "content": content,
        "tags": tags,
        "embedding": embedding or [],
        "priority": priority,
        "category": category,
        "created_at": result["created_at"].isoformat(),
        "updated_at": None
    }

    # åŒæ—¶æ›´æ–°ç¼“å­˜
    add_to_cache(memory_data)
    print(f"[CACHE] å·²æ·»åŠ è®°å¿† #{result['id']} åˆ°ç¼“å­˜", flush=True)

    return memory_data


def update_memory_in_db(memory_id: int, content: str = None, tags: list = None, priority: int = None, category: str = None) -> dict | None:
    """æ›´æ–°æ•°æ®åº“ä¸­çš„è®°å¿†å¹¶æ›´æ–°ç¼“å­˜"""
    conn = get_db_connection()
    cur = conn.cursor()

    # å…ˆè·å–åŸè®°å¿†
    cur.execute("SELECT id, content, tags, priority, category FROM memories WHERE id = %s", (memory_id,))
    existing = cur.fetchone()

    if not existing:
        cur.close()
        conn.close()
        return None

    # ä½¿ç”¨åŸå€¼æˆ–æ–°å€¼
    new_content = content if content is not None else existing["content"]
    new_tags = tags if tags is not None else existing["tags"]
    new_priority = priority if priority is not None else existing.get("priority", 3)
    new_category = category if category is not None else existing.get("category", "general")

    # å¦‚æœå†…å®¹å˜äº†ï¼Œé‡æ–°ç”Ÿæˆ embedding
    new_embedding = None
    if content is not None and content != existing["content"]:
        new_embedding = get_embedding(new_content)

    # æ›´æ–°è®°å½•
    if new_embedding:
        cur.execute(
            "UPDATE memories SET content = %s, tags = %s, embedding = %s, priority = %s, category = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s RETURNING updated_at",
            (new_content, new_tags, new_embedding, new_priority, new_category, memory_id)
        )
    else:
        cur.execute(
            "UPDATE memories SET content = %s, tags = %s, priority = %s, category = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s RETURNING updated_at",
            (new_content, new_tags, new_priority, new_category, memory_id)
        )

    result = cur.fetchone()
    conn.commit()
    cur.close()
    conn.close()

    updated_at = result["updated_at"].isoformat() if result else None

    # åŒæ—¶æ›´æ–°ç¼“å­˜
    cache_updates = {
        "content": new_content,
        "tags": new_tags,
        "priority": new_priority,
        "category": new_category,
        "updated_at": updated_at
    }
    if new_embedding:
        cache_updates["embedding"] = new_embedding
    update_cache(memory_id, **cache_updates)

    return {
        "id": memory_id,
        "content": new_content,
        "tags": new_tags,
        "priority": new_priority,
        "category": new_category,
        "updated_at": updated_at
    }


def delete_memory_by_id(memory_id: int) -> bool:
    """ä»æ•°æ®åº“åˆ é™¤è®°å¿†å¹¶æ›´æ–°ç¼“å­˜"""
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute("DELETE FROM memories WHERE id = %s", (memory_id,))
    deleted = cur.rowcount > 0
    conn.commit()
    cur.close()
    conn.close()

    # åŒæ—¶æ›´æ–°ç¼“å­˜
    if deleted:
        remove_from_cache(memory_id)

    return deleted


def search_memories(query: str, memories: list[dict], category: str = None) -> list[tuple[float, dict]]:
    """æ··åˆæœç´¢ - è¯­ä¹‰æœç´¢ + å…³é”®è¯æœç´¢ + å¤šè¯­è¨€ç¿»è¯‘

    æ”¯æŒè·¨è¯­è¨€æœç´¢ï¼šè‡ªåŠ¨ç¿»è¯‘æŸ¥è¯¢è¯ï¼Œç”¨å¤šè¯­è¨€åŒæ—¶æœç´¢
    category å‚æ•°ç”¨äºåŠ æƒï¼ˆåŒ¹é…çš„åˆ†ç±»ä¼šåŠ åˆ†ï¼‰ï¼Œè€Œä¸æ˜¯ç¡¬è¿‡æ»¤
    """
    # çº¯å…³é”®è¯æ¨¡å¼
    if SEARCH_MODE == "keyword":
        return search_memories_keyword(query, memories, MAX_RESULTS, category=category)

    # è·å–ç¿»è¯‘ï¼ˆå¤šè¯­è¨€æŸ¥è¯¢ï¼‰
    all_queries = [query] + translate_query(query)
    print(f"[SEARCH] å¤šè¯­è¨€æŸ¥è¯¢: {all_queries}", flush=True)

    # ç”¨ dict å­˜å‚¨æ¯ä¸ªè®°å¿†çš„æœ€é«˜åˆ†ï¼ˆé¿å…é‡å¤ï¼‰
    scores_by_id = {}

    for q in all_queries:
        q_embedding = get_embedding(q)
        q_lower = q.lower()

        for m in memories:
            memory_id = m["id"]
            semantic_score = 0
            keyword_score = 0

            # 1. è¯­ä¹‰ç›¸ä¼¼åº¦
            if q_embedding and m.get("embedding"):
                semantic_score = cosine_similarity(q_embedding, m["embedding"])

            # 2. å…³é”®è¯åŒ¹é…ï¼ˆcontent + tagsï¼‰
            content_lower = m["content"].lower()

            # content å®Œå…¨åŒ¹é…
            if q_lower in content_lower:
                keyword_score += 0.3

            # tags åŒ¹é…
            for tag in m.get("tags", []):
                if q_lower in tag.lower() or tag.lower() in q_lower:
                    keyword_score += 0.25

            # åˆ†è¯åŒ¹é…
            for word in q_lower.split():
                if len(word) >= 2 and word in content_lower:
                    keyword_score += 0.1

            # 3. ä¼˜å…ˆçº§åŠ æˆ
            priority_boost = (6 - m.get("priority", 3)) * 0.05

            # 4. åˆ†ç±»åŠ æˆï¼ˆå¦‚æœæŒ‡å®šäº† categoryï¼ŒåŒ¹é…çš„åŠ åˆ†ï¼‰
            category_boost = 0
            if category and m.get("category", "general") == category:
                category_boost = 0.15

            # 5. ç»¼åˆå¾—åˆ†
            base_score = max(semantic_score, keyword_score)
            if semantic_score > 0.3 and keyword_score > 0:
                base_score += 0.1

            final_score = base_score + priority_boost + category_boost

            # ä¿ç•™æœ€é«˜åˆ†
            if final_score > 0.25:
                if memory_id not in scores_by_id or final_score > scores_by_id[memory_id][0]:
                    scores_by_id[memory_id] = (final_score, m)

    # æ’åºè¿”å›
    results = list(scores_by_id.values())
    results.sort(key=lambda x: x[0], reverse=True)

    return results[:MAX_RESULTS]


def search_memories_keyword(query: str, memories: list[dict], top_k: int = None, category: str = None) -> list[tuple[float, dict]]:
    """å…³é”®è¯æœç´¢ï¼ˆå¤‡ç”¨ï¼‰ï¼Œè¿”å› (åˆ†æ•°, è®°å¿†) åˆ—è¡¨

    category å‚æ•°ç”¨äºåŠ æƒï¼Œè€Œä¸æ˜¯ç¡¬è¿‡æ»¤
    """
    query_lower = query.lower()
    scored = []

    for m in memories:
        score = 0
        content_lower = m["content"].lower()

        if query_lower in content_lower:
            score += 10

        for tag in m.get("tags", []):
            if query_lower in tag.lower():
                score += 5

        for word in query_lower.split():
            if word in content_lower:
                score += 2

        # ä¼˜å…ˆçº§åŠ æˆ
        priority_boost = (6 - m.get("priority", 3))  # 1-5 å¯¹åº” 5-1
        score += priority_boost

        # åˆ†ç±»åŠ æˆï¼ˆå¦‚æœæŒ‡å®šäº† categoryï¼ŒåŒ¹é…çš„åŠ åˆ†ï¼‰
        if category and m.get("category", "general") == category:
            score += 3

        if score > 0:
            scored.append((score, m))

    scored.sort(key=lambda x: x[0], reverse=True)
    return scored[:top_k or MAX_RESULTS]


def get_memory_stats(memories: list[dict]) -> dict:
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    if not memories:
        return {
            "total": 0,
            "by_category": {},
            "by_priority": {},
            "by_tag": {},
            "with_embedding": 0
        }

    by_category = {}
    by_priority = {}
    by_tag = {}
    with_embedding = 0

    for m in memories:
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        cat = m.get("category", "general")
        by_category[cat] = by_category.get(cat, 0) + 1

        # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
        pri = str(m.get("priority", 3))
        by_priority[pri] = by_priority.get(pri, 0) + 1

        # æŒ‰æ ‡ç­¾ç»Ÿè®¡
        for tag in m.get("tags", []):
            by_tag[tag] = by_tag.get(tag, 0) + 1

        # ç»Ÿè®¡æœ‰ embedding çš„è®°å¿†
        if m.get("embedding"):
            with_embedding += 1

    return {
        "total": len(memories),
        "by_category": by_category,
        "by_priority": by_priority,
        "by_tag": by_tag,
        "with_embedding": with_embedding
    }


# é¢„å®šä¹‰çš„è®°å¿†åˆ†ç±»
MEMORY_CATEGORIES = ["general", "preference", "work", "personal", "habit", "skill", "goal"]

# ä¼˜å…ˆçº§è¯´æ˜
PRIORITY_LEVELS = {
    1: "æœ€é«˜ - æ ¸å¿ƒä¸ªäººä¿¡æ¯",
    2: "é«˜ - é‡è¦åå¥½æˆ–ä¹ æƒ¯",
    3: "ä¸­ - ä¸€èˆ¬ä¿¡æ¯ï¼ˆé»˜è®¤ï¼‰",
    4: "ä½ - ä¸´æ—¶æˆ–æ¬¡è¦ä¿¡æ¯",
    5: "æœ€ä½ - å¯èƒ½è¿‡æ—¶çš„ä¿¡æ¯"
}


def get_tool_name(base_name: str) -> str:
    """ç”Ÿæˆå¸¦å‰ç¼€çš„å·¥å…·åç§°"""
    return f"{TOOL_PREFIX}{base_name}"


@server.list_tools()
async def list_tools() -> list[Tool]:
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·ï¼ˆç²¾ç®€æè¿°ä»¥å‡å°‘ token æ¶ˆè€—ï¼‰"""
    p = f"[{TOOL_PREFIX.rstrip('_')}] " if TOOL_PREFIX else ""

    return [
        Tool(
            name=get_tool_name("recall_memory"),
            description=f"{p}Search memories. Use when user asks about past conversations or stored info.",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search keywords"},
                    "category": {"type": "string", "enum": MEMORY_CATEGORIES}
                },
                "required": ["query"]
            }
        ),
        Tool(
            name=get_tool_name("save_memory"),
            description=f"{p}Save important user info (preferences, habits, work, personal).",
            inputSchema={
                "type": "object",
                "properties": {
                    "content": {"type": "string", "description": "Memory content"},
                    "tags": {"type": "array", "items": {"type": "string"}},
                    "priority": {"type": "integer", "minimum": 1, "maximum": 5, "description": "1=highest 5=lowest"},
                    "category": {"type": "string", "enum": MEMORY_CATEGORIES}
                },
                "required": ["content"]
            }
        ),
        Tool(
            name=get_tool_name("update_memory"),
            description=f"{p}Update existing memory by ID.",
            inputSchema={
                "type": "object",
                "properties": {
                    "memory_id": {"type": "integer"},
                    "content": {"type": "string"},
                    "tags": {"type": "array", "items": {"type": "string"}},
                    "priority": {"type": "integer", "minimum": 1, "maximum": 5},
                    "category": {"type": "string", "enum": MEMORY_CATEGORIES}
                },
                "required": ["memory_id"]
            }
        ),
        Tool(
            name=get_tool_name("list_all_memories"),
            description=f"{p}List all saved memories.",
            inputSchema={
                "type": "object",
                "properties": {
                    "category": {"type": "string", "enum": MEMORY_CATEGORIES}
                }
            }
        ),
        Tool(
            name=get_tool_name("delete_memory"),
            description=f"{p}Delete memory by ID.",
            inputSchema={
                "type": "object",
                "properties": {
                    "memory_id": {"type": "integer"}
                },
                "required": ["memory_id"]
            }
        ),
        Tool(
            name=get_tool_name("memory_stats"),
            description=f"{p}Show memory statistics.",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name=get_tool_name("reset_session"),
            description=f"{p}Reset memory session. Use at start of new conversation.",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name=get_tool_name("regenerate_embeddings"),
            description=f"{p}Regenerate all embeddings (use after changing embedding model).",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]


def format_priority(priority: int) -> str:
    """æ ¼å¼åŒ–ä¼˜å…ˆçº§æ˜¾ç¤º"""
    symbols = {1: "â˜…â˜…â˜…", 2: "â˜…â˜…â˜†", 3: "â˜…â˜†â˜†", 4: "â˜†â˜†â˜†", 5: "Â·"}
    return symbols.get(priority, "â˜…â˜†â˜†")


def get_base_tool_name(name: str) -> str:
    """ä»å¸¦å‰ç¼€çš„å·¥å…·åä¸­æå–åŸºç¡€åç§°"""
    if TOOL_PREFIX and name.startswith(TOOL_PREFIX):
        return name[len(TOOL_PREFIX):]
    return name


@server.call_tool()
async def call_tool(name: str, arguments: dict) -> list[TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    global RECALL_COUNTER  # ç§»åˆ°å‡½æ•°å¼€å§‹å¤„

    # æå–åŸºç¡€å·¥å…·åï¼ˆå»æ‰å‰ç¼€ï¼‰
    base_name = get_base_tool_name(name)

    if base_name == "recall_memory":
        query = arguments.get("query", "")
        category = arguments.get("category")

        # æœåŠ¡ç«¯è¿½è¸ªè°ƒç”¨æ¬¡æ•°ï¼ˆæ¸è¿›å¼æ³¨å…¥ï¼‰
        now = datetime.now()

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°ä¼šè¯ï¼ˆè¶…è¿‡ 5 åˆ†é’Ÿæ²¡è°ƒç”¨ï¼‰
        if RECALL_COUNTER["last_call"] is None:
            RECALL_COUNTER = {"count": 1, "last_call": now}
        else:
            time_diff = (now - RECALL_COUNTER["last_call"]).total_seconds()
            if time_diff > RECALL_SESSION_TIMEOUT:
                # æ–°ä¼šè¯ï¼Œé‡ç½®è®¡æ•°
                RECALL_COUNTER = {"count": 1, "last_call": now}
            else:
                # åŒä¸€ä¼šè¯ï¼Œè®¡æ•° +1
                RECALL_COUNTER["count"] += 1
                RECALL_COUNTER["last_call"] = now

        recall_count = RECALL_COUNTER["count"]

        # è°ƒè¯•æ—¥å¿—
        print(f"[RECALL] query={query}, category={category}, recall_count={recall_count}, raw_args={arguments}", flush=True)

        memories = get_cached_memories()

        if not memories:
            return [TextContent(type="text", text="æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®°å¿†ã€‚")]

        # æœç´¢è®°å¿†ï¼ˆæ ¹æ® SEARCH_MODE è‡ªåŠ¨é€‰æ‹©è¯­ä¹‰æˆ–å…³é”®è¯æœç´¢ï¼‰
        results = search_memories(query, memories, category=category)

        if not results:
            cat_hint = f"ï¼ˆåˆ†ç±»: {category}ï¼‰" if category else ""
            return [TextContent(type="text", text=f"æ²¡æœ‰æ‰¾åˆ°ä¸ã€Œ{query}ã€ç›¸å…³çš„è®°å¿†{cat_hint}ã€‚")]

        # æ¸è¿›å¼æ³¨å…¥ï¼ˆæ–°ç‰ˆï¼‰
        # ç¬¬ 1 æ¬¡: è¿”å› 3 æ¡æ ¸å¿ƒè®°å¿†ï¼ˆèº«ä»½/å…³ç³»/è¯­è¨€é£æ ¼ - ä¼˜å…ˆçº§ 1-2 æˆ– personal åˆ†ç±»ï¼‰
        # ç¬¬ 2 æ¬¡: è¿”å› 1 æ¡æœ€ç›¸å…³çš„ï¼Œæç¤ºè¿˜æœ‰å‡ æ¡ç›¸å…³è®°å¿†
        # ç¬¬ 3+ æ¬¡: è¿”å› MAX_RESULTS æ¡ï¼Œç”±æ¨¡å‹è‡ªè¡Œåˆ¤æ–­

        total_related = len(results)  # è®°å½•æ€»ç›¸å…³æ•°é‡

        if recall_count == 1:
            # ç¬¬ä¸€æ¬¡ï¼šä¼˜å…ˆè¿”å›æ ¸å¿ƒè®°å¿†ï¼ˆèº«ä»½ç¡®è®¤ã€å…³ç³»ç¡®è®¤ã€è¯­è¨€é£æ ¼ï¼‰
            # ç­›é€‰ä¼˜å…ˆçº§ 1-2 æˆ– personal åˆ†ç±»çš„è®°å¿†
            core_memories = [
                (score, m) for score, m in results
                if m.get("priority", 3) <= 2 or m.get("category") == "personal"
            ]

            if core_memories:
                # æœ‰æ ¸å¿ƒè®°å¿†ï¼Œè¿”å›æœ€å¤š 3 æ¡
                display_results = core_memories[:3]
            else:
                # æ²¡æœ‰æ ¸å¿ƒè®°å¿†ï¼Œè¿”å›ç›¸å…³åº¦æœ€é«˜çš„ 3 æ¡
                display_results = results[:3]

            result = "ğŸ“Œ æ ¸å¿ƒè®°å¿†:\n"
            for i, (score, m) in enumerate(display_results, 1):
                tags_str = ", ".join(m.get("tags", [])[:3]) if m.get("tags") else ""
                content_short = m["content"][:50] + "..." if len(m["content"]) > 50 else m["content"]
                result += f"{i}. {content_short}"
                if tags_str:
                    result += f" ({tags_str})"
                result += "\n"

            if total_related > len(display_results):
                result += f"\nğŸ’¡ è¿˜æœ‰ {total_related - len(display_results)} æ¡ç›¸å…³è®°å¿†"

            return [TextContent(type="text", text=result.strip())]

        elif recall_count == 2:
            # ç¬¬äºŒæ¬¡ï¼šè¿”å›ä¸å½“å‰è¯é¢˜æœ€ç›¸å…³çš„ 1 æ¡ï¼Œæç¤ºè¿˜æœ‰å‡ æ¡
            score, top_mem = results[0]
            tags_str = ", ".join(top_mem.get("tags", [])) if top_mem.get("tags") else ""
            priority_str = format_priority(top_mem.get("priority", 3))

            result = f"ğŸ¯ æœ€ç›¸å…³è®°å¿†:\n{top_mem['content']}"
            if tags_str:
                result += f"\næ ‡ç­¾: {tags_str}"
            result += f"\nä¼˜å…ˆçº§: {priority_str} | åˆ†ç±»: {top_mem.get('category', 'general')}"

            if total_related > 1:
                result += f"\n\nğŸ’¡ æ­¤è¯é¢˜è¿˜æœ‰ {total_related - 1} æ¡ç›¸å…³è®°å¿†"
                result += f"\nğŸ“‹ ä½¿ç”¨ list_all_memories å¯æŸ¥çœ‹å…¨éƒ¨è®°å¿†"

            return [TextContent(type="text", text=result)]

        else:
            # ç¬¬ 3+ æ¬¡ï¼šè¿”å› MAX_RESULTS æ¡ï¼Œæ­£å¸¸æ˜¾ç¤º
            display_results = results[:MAX_RESULTS]

            result = f"ğŸ” æ‰¾åˆ° {total_related} æ¡ç›¸å…³è®°å¿†:\n"
            for i, (score, m) in enumerate(display_results, 1):
                tags_str = ", ".join(m.get("tags", [])[:2]) if m.get("tags") else ""
                content_short = m["content"][:40] + "..." if len(m["content"]) > 40 else m["content"]
                result += f"{i}. {content_short}"
                if tags_str:
                    result += f" ({tags_str})"
                result += "\n"

            if total_related > MAX_RESULTS:
                result += f"\n(æ˜¾ç¤ºå‰ {MAX_RESULTS} æ¡ï¼Œå…± {total_related} æ¡ç›¸å…³)"

            return [TextContent(type="text", text=result.strip())]

    elif base_name == "save_memory":
        content = arguments.get("content", "")
        tags = arguments.get("tags", [])
        priority = arguments.get("priority", 3)
        category = arguments.get("category", "general")

        if not content:
            return [TextContent(type="text", text="è®°å¿†å†…å®¹ä¸èƒ½ä¸ºç©ºã€‚")]

        # éªŒè¯ä¼˜å…ˆçº§
        if priority < 1 or priority > 5:
            priority = 3

        # éªŒè¯åˆ†ç±»
        if category not in MEMORY_CATEGORIES:
            category = "general"

        new_memory = save_memory_to_db(content, tags, priority, category)
        priority_str = format_priority(priority)
        return [TextContent(type="text", text=f"å·²ä¿å­˜è®°å¿† [{new_memory['id']}]: {content}\nä¼˜å…ˆçº§: {priority_str} | åˆ†ç±»: {category}")]

    elif base_name == "update_memory":
        memory_id = arguments.get("memory_id")
        content = arguments.get("content")
        tags = arguments.get("tags")
        priority = arguments.get("priority")
        category = arguments.get("category")

        if memory_id is None:
            return [TextContent(type="text", text="è¯·æä¾›è¦æ›´æ–°çš„è®°å¿† IDã€‚")]

        # éªŒè¯ä¼˜å…ˆçº§
        if priority is not None and (priority < 1 or priority > 5):
            return [TextContent(type="text", text="ä¼˜å…ˆçº§å¿…é¡»åœ¨ 1-5 ä¹‹é—´ã€‚")]

        # éªŒè¯åˆ†ç±»
        if category is not None and category not in MEMORY_CATEGORIES:
            return [TextContent(type="text", text=f"åˆ†ç±»å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {', '.join(MEMORY_CATEGORIES)}")]

        updated = update_memory_in_db(memory_id, content, tags, priority, category)

        if not updated:
            return [TextContent(type="text", text=f"æœªæ‰¾åˆ° ID ä¸º {memory_id} çš„è®°å¿†ã€‚")]

        result = f"å·²æ›´æ–°è®°å¿† [{memory_id}]:\n"
        result += f"- å†…å®¹: {updated['content']}\n"
        result += f"- æ ‡ç­¾: {', '.join(updated['tags']) if updated['tags'] else 'æ— '}\n"
        result += f"- ä¼˜å…ˆçº§: {format_priority(updated['priority'])}\n"
        result += f"- åˆ†ç±»: {updated['category']}"

        return [TextContent(type="text", text=result)]

    elif base_name == "list_all_memories":
        category = arguments.get("category")
        memories = get_cached_memories()

        # æŒ‰åˆ†ç±»ç­›é€‰
        if category:
            memories = [m for m in memories if m.get("category", "general") == category]

        if not memories:
            cat_hint = f"ï¼ˆåˆ†ç±»: {category}ï¼‰" if category else ""
            return [TextContent(type="text", text=f"ç›®å‰æ²¡æœ‰ä¿å­˜ä»»ä½•è®°å¿†{cat_hint}ã€‚")]

        result = f"å…±æœ‰ {len(memories)} æ¡è®°å¿†"
        if category:
            result += f"ï¼ˆåˆ†ç±»: {category}ï¼‰"
        result += "ï¼š\n"

        for m in memories:
            tags_str = ", ".join(m.get("tags", [])) if m.get("tags") else "æ— "
            priority_str = format_priority(m.get("priority", 3))
            cat_str = m.get("category", "general")
            result += f"- [{m['id']}] {priority_str} {m['content']}\n"
            result += f"  â”” åˆ†ç±»: {cat_str} | æ ‡ç­¾: {tags_str}\n"

        return [TextContent(type="text", text=result)]

    elif base_name == "delete_memory":
        memory_id = arguments.get("memory_id")

        if memory_id is None:
            return [TextContent(type="text", text="è¯·æä¾›è¦åˆ é™¤çš„è®°å¿† IDã€‚")]

        if delete_memory_by_id(memory_id):
            return [TextContent(type="text", text=f"å·²åˆ é™¤è®°å¿† [{memory_id}]ã€‚")]
        else:
            return [TextContent(type="text", text=f"æœªæ‰¾åˆ° ID ä¸º {memory_id} çš„è®°å¿†ã€‚")]

    elif base_name == "reset_session":
        old_count = RECALL_COUNTER["count"]
        RECALL_COUNTER = {"count": 0, "last_call": None}
        print(f"[RESET] Session reset. Previous recall_count was {old_count}", flush=True)
        return [TextContent(type="text", text=f"ä¼šè¯å·²é‡ç½®ã€‚(ä¹‹å‰è°ƒç”¨æ¬¡æ•°: {old_count})")]

    elif base_name == "memory_stats":
        memories = get_cached_memories()
        stats = get_memory_stats(memories)

        if stats["total"] == 0:
            return [TextContent(type="text", text="ç›®å‰æ²¡æœ‰ä¿å­˜ä»»ä½•è®°å¿†ã€‚")]

        result = "ğŸ“Š è®°å¿†ç»Ÿè®¡\n"
        result += "=" * 30 + "\n"
        result += f"æ€»è®°å¿†æ•°: {stats['total']}\n"
        result += f"è¯­ä¹‰æœç´¢æ”¯æŒ: {stats['with_embedding']}/{stats['total']}\n\n"

        result += "æŒ‰åˆ†ç±»:\n"
        for cat, count in sorted(stats["by_category"].items()):
            result += f"  - {cat}: {count}\n"

        result += "\næŒ‰ä¼˜å…ˆçº§:\n"
        for pri in ["1", "2", "3", "4", "5"]:
            if pri in stats["by_priority"]:
                result += f"  - {format_priority(int(pri))} ({pri}): {stats['by_priority'][pri]}\n"

        if stats["by_tag"]:
            result += "\nçƒ­é—¨æ ‡ç­¾ (Top 5):\n"
            sorted_tags = sorted(stats["by_tag"].items(), key=lambda x: x[1], reverse=True)[:5]
            for tag, count in sorted_tags:
                result += f"  - {tag}: {count}\n"

        return [TextContent(type="text", text=result)]

    elif base_name == "regenerate_embeddings":
        # é‡æ–°ç”Ÿæˆæ‰€æœ‰è®°å¿†çš„ embeddingï¼ˆåˆ‡æ¢æ¨¡å‹åä½¿ç”¨ï¼‰
        memories = get_cached_memories()
        if not memories:
            return [TextContent(type="text", text="æ²¡æœ‰è®°å¿†éœ€è¦é‡æ–°ç”Ÿæˆã€‚")]

        updated = 0
        failed = 0
        for m in memories:
            try:
                new_embedding = get_embedding(m["content"], use_cache=False)
                if new_embedding:
                    # æ›´æ–°æ•°æ®åº“
                    conn = get_db_connection()
                    cur = conn.cursor()
                    cur.execute("UPDATE memories SET embedding = %s WHERE id = %s", (new_embedding, m["id"]))
                    conn.commit()
                    cur.close()
                    conn.close()
                    # æ›´æ–°ç¼“å­˜
                    m["embedding"] = new_embedding
                    updated += 1
                    print(f"[REGEN] å·²æ›´æ–°è®°å¿† #{m['id']} çš„ embedding (ç»´åº¦: {len(new_embedding)})", flush=True)
                else:
                    failed += 1
            except Exception as e:
                print(f"[REGEN ERROR] è®°å¿† #{m['id']}: {e}", flush=True)
                failed += 1

        result = f"âœ… Embedding é‡æ–°ç”Ÿæˆå®Œæˆ\n"
        result += f"- æˆåŠŸ: {updated}\n"
        result += f"- å¤±è´¥: {failed}\n"
        if updated > 0:
            # è·å–æ–°çš„ç»´åº¦
            sample_dim = len(memories[0].get("embedding", [])) if memories else 0
            result += f"- æ–°ç»´åº¦: {sample_dim}"
        return [TextContent(type="text", text=result)]

    return [TextContent(type="text", text=f"æœªçŸ¥å·¥å…·: {name}")]


# åˆ›å»º SSE transport
sse = SseServerTransport("/messages/")


async def handle_sse(request):
    """å¤„ç† SSE è¿æ¥"""
    async with sse.connect_sse(
        request.scope, request.receive, request._send
    ) as streams:
        await server.run(
            streams[0], streams[1], server.create_initialization_options()
        )


async def health_check(request):
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    embedding_status = "enabled" if GEMINI_API_KEY else "disabled"
    return JSONResponse({
        "status": "ok",
        "service": "memory-mcp",
        "storage": "postgresql",
        "semantic_search": embedding_status
    })


# åˆ›å»º Starlette åº”ç”¨
app = Starlette(
    routes=[
        Route("/health", health_check),
        Route("/sse", handle_sse),
        Mount("/messages/", app=sse.handle_post_message),
    ]
)


if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    if DATABASE_URL:
        print("åˆå§‹åŒ–æ•°æ®åº“...")
        init_db()
        print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")

        # åˆå§‹åŒ–è®°å¿†ç¼“å­˜
        print("åŠ è½½è®°å¿†ç¼“å­˜...")
        init_memory_cache()

        # æ£€æµ‹ embedding ç»´åº¦ï¼Œå¦‚æœæ˜¯æ—§ç‰ˆï¼ˆ768ç»´ï¼‰åˆ™è‡ªåŠ¨é‡æ–°ç”Ÿæˆ
        if GEMINI_API_KEY and _memory_cache:
            sample = _memory_cache[0].get("embedding", [])
            if sample and len(sample) == 768:
                print(f"[AUTO-REGEN] æ£€æµ‹åˆ°æ—§ç‰ˆ embedding (768ç»´)ï¼Œæ­£åœ¨è‡ªåŠ¨å‡çº§åˆ° 3072 ç»´...")
                updated = 0
                for m in _memory_cache:
                    try:
                        new_embedding = get_embedding(m["content"], use_cache=False)
                        if new_embedding:
                            conn = get_db_connection()
                            cur = conn.cursor()
                            cur.execute("UPDATE memories SET embedding = %s WHERE id = %s", (new_embedding, m["id"]))
                            conn.commit()
                            cur.close()
                            conn.close()
                            m["embedding"] = new_embedding
                            updated += 1
                    except Exception as e:
                        print(f"[AUTO-REGEN ERROR] è®°å¿† #{m['id']}: {e}", flush=True)
                print(f"[AUTO-REGEN] å®Œæˆï¼å·²æ›´æ–° {updated} æ¡è®°å¿†çš„ embedding")
            elif sample:
                print(f"[EMBEDDING] å½“å‰ç»´åº¦: {len(sample)} (å·²æ˜¯æœ€æ–°)")
    else:
        print("è­¦å‘Š: æœªè®¾ç½® DATABASE_URLï¼Œå°†æ— æ³•ä¿å­˜æ•°æ®")

    if GEMINI_API_KEY:
        print(f"Gemini Embedding: å·²å¯ç”¨ (ç¼“å­˜ä¸Šé™: {EMBEDDING_CACHE_MAX_SIZE})")
    else:
        print("Gemini Embedding: æœªå¯ç”¨ï¼ˆå°†ä½¿ç”¨å…³é”®è¯æœç´¢ï¼‰")

    print(f"æœç´¢æ¨¡å¼: {SEARCH_MODE} ({'è¯­ä¹‰æœç´¢' if SEARCH_MODE == 'semantic' else 'å…³é”®è¯æœç´¢'})")
    print(f"è¿”å›ç»“æœæ•°: {MAX_RESULTS}")

    # Railway ä½¿ç”¨ PORT ç¯å¢ƒå˜é‡
    port = int(os.environ.get("PORT", 8000))

    print("=" * 50)
    print("Memory MCP Server (PostgreSQL + Embedding)")
    print("=" * 50)
    print(f"æœåŠ¡åç§°: {server_name}")
    print(f"æœåŠ¡ç«¯å£: {port}")
    print(f"å·¥å…·å‰ç¼€: {TOOL_PREFIX if TOOL_PREFIX else '(æ— )'}")
    print("SSE ç«¯ç‚¹: /sse")
    print("å¥åº·æ£€æŸ¥: /health")
    print("=" * 50)

    uvicorn.run(app, host="0.0.0.0", port=port)
